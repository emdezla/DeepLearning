{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "merged_files",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4d95a934108e4d8fad7de0a4ab0af16f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4666f39832bf4ab4ac5af5dc6d414c9c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a352a3669a194121bedeb4d993e34788",
              "IPY_MODEL_676525c8f82144abacc57161cd09a65e"
            ]
          }
        },
        "4666f39832bf4ab4ac5af5dc6d414c9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a352a3669a194121bedeb4d993e34788": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_85ad8c4bb2bb48e0a39aca819fe703e3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_633791c1436c42dcaa7b14726b8dd2dd"
          }
        },
        "676525c8f82144abacc57161cd09a65e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e6f98fa1e8984f15820e25650814e3cf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9920512/? [00:04&lt;00:00, 2398160.34it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_593f05ac707b477292b17882931ce6f5"
          }
        },
        "85ad8c4bb2bb48e0a39aca819fe703e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "633791c1436c42dcaa7b14726b8dd2dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e6f98fa1e8984f15820e25650814e3cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "593f05ac707b477292b17882931ce6f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0aa8c14b66f84c26b4a3bd5f005f80a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fa1440cf880244d099277302ae8e7085",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0d4a1cd22b744c96abe7381f879c17e8",
              "IPY_MODEL_03e3e5692abe4db0ac33b3a782a34ccf"
            ]
          }
        },
        "fa1440cf880244d099277302ae8e7085": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0d4a1cd22b744c96abe7381f879c17e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d852317b021f4f7c849e7890b553651f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cf572e6951d846ac992fcb755e41c5d0"
          }
        },
        "03e3e5692abe4db0ac33b3a782a34ccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ad9e7448e8284a74b45257c44302e4cc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 32768/? [00:02&lt;00:00, 15658.45it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c31661b8b6ca4ab4b4ccc7ad603925f1"
          }
        },
        "d852317b021f4f7c849e7890b553651f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cf572e6951d846ac992fcb755e41c5d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ad9e7448e8284a74b45257c44302e4cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c31661b8b6ca4ab4b4ccc7ad603925f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "40060efacfb840dc9e4244330e8a1d70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_adc829eabd9948c58cfc6b20fe1ba022",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_21c414d107e64ecb8c733dd02aa54436",
              "IPY_MODEL_0bc23053f4084230be425800ec288e29"
            ]
          }
        },
        "adc829eabd9948c58cfc6b20fe1ba022": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "21c414d107e64ecb8c733dd02aa54436": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ccd7480dafd044feaa0581f807b458ad",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_39081b5847a741628efdce9d84df0b38"
          }
        },
        "0bc23053f4084230be425800ec288e29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_825bb05a8cc74691b3732c8d95bf97e5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1654784/? [00:01&lt;00:00, 935295.89it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a57294f1d5094cbf9fba77d11ba57670"
          }
        },
        "ccd7480dafd044feaa0581f807b458ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "39081b5847a741628efdce9d84df0b38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "825bb05a8cc74691b3732c8d95bf97e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a57294f1d5094cbf9fba77d11ba57670": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6c3bb7ad220d4bf881603d33f531fc87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1a5a694a982d44a9861fa1898e5a9278",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2b4edce71af74b7699ef9741c604e3c4",
              "IPY_MODEL_1631514c74de461d9637aacce39fb0fa"
            ]
          }
        },
        "1a5a694a982d44a9861fa1898e5a9278": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2b4edce71af74b7699ef9741c604e3c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4422ba6111344a3587acc4080cafc308",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ac8754686f644e36853d77f4e0f7c22f"
          }
        },
        "1631514c74de461d9637aacce39fb0fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e2bac35bab3d4216b21e6cff9f7880b7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8192/? [00:00&lt;00:00, 8699.03it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b2527ef013294ed883c88771f1599688"
          }
        },
        "4422ba6111344a3587acc4080cafc308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ac8754686f644e36853d77f4e0f7c22f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e2bac35bab3d4216b21e6cff9f7880b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b2527ef013294ed883c88771f1599688": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zI901RWuUhy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "0642f51d-8517-444f-df2d-6867ef57bc8c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import sys\n",
        "sys.path.append('/content/gdrive/My Drive/Colab Notebooks')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7ucl_T5uwun",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import statistics\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from itertools import accumulate\n",
        "import dlc_practical_prologue as prologue"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvcNe9-xTyWt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373,
          "referenced_widgets": [
            "4d95a934108e4d8fad7de0a4ab0af16f",
            "4666f39832bf4ab4ac5af5dc6d414c9c",
            "a352a3669a194121bedeb4d993e34788",
            "676525c8f82144abacc57161cd09a65e",
            "85ad8c4bb2bb48e0a39aca819fe703e3",
            "633791c1436c42dcaa7b14726b8dd2dd",
            "e6f98fa1e8984f15820e25650814e3cf",
            "593f05ac707b477292b17882931ce6f5",
            "0aa8c14b66f84c26b4a3bd5f005f80a9",
            "fa1440cf880244d099277302ae8e7085",
            "0d4a1cd22b744c96abe7381f879c17e8",
            "03e3e5692abe4db0ac33b3a782a34ccf",
            "d852317b021f4f7c849e7890b553651f",
            "cf572e6951d846ac992fcb755e41c5d0",
            "ad9e7448e8284a74b45257c44302e4cc",
            "c31661b8b6ca4ab4b4ccc7ad603925f1",
            "40060efacfb840dc9e4244330e8a1d70",
            "adc829eabd9948c58cfc6b20fe1ba022",
            "21c414d107e64ecb8c733dd02aa54436",
            "0bc23053f4084230be425800ec288e29",
            "ccd7480dafd044feaa0581f807b458ad",
            "39081b5847a741628efdce9d84df0b38",
            "825bb05a8cc74691b3732c8d95bf97e5",
            "a57294f1d5094cbf9fba77d11ba57670",
            "6c3bb7ad220d4bf881603d33f531fc87",
            "1a5a694a982d44a9861fa1898e5a9278",
            "2b4edce71af74b7699ef9741c604e3c4",
            "1631514c74de461d9637aacce39fb0fa",
            "4422ba6111344a3587acc4080cafc308",
            "ac8754686f644e36853d77f4e0f7c22f",
            "e2bac35bab3d4216b21e6cff9f7880b7",
            "b2527ef013294ed883c88771f1599688"
          ]
        },
        "outputId": "fe19ab49-86c8-42d5-c215-bdb1c1b8b6f4"
      },
      "source": [
        "torch.backends.cudnn.deterministic=True\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "\n",
        "N = 1000\n",
        "train_input, train_target, train_classes, test_input, test_target, test_classes = prologue.generate_pair_sets(N)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d95a934108e4d8fad7de0a4ab0af16f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/mnist/MNIST/raw/train-images-idx3-ubyte.gz to ./data/mnist/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0aa8c14b66f84c26b4a3bd5f005f80a9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/mnist/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "40060efacfb840dc9e4244330e8a1d70",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/mnist/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c3bb7ad220d4bf881603d33f531fc87",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/mnist/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zx_nq_Bako4u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "63e75b36-ee3e-4cbe-e432-d4b8e6b6578e"
      },
      "source": [
        "#FLATTENING INPUT TO BE USED FOR FULLY CONNECTED NETWORK\n",
        "train_input_first_approach =  torch.zeros(size = (1000,392))\n",
        "test_input_first_approach = torch.zeros(size = (1000,392))\n",
        "\n",
        "for i in range(train_input.size(0)):\n",
        "  \n",
        "    train_input_first_approach[i]  = torch.cat((torch.flatten(train_input[i,0]),torch.flatten(train_input[i,1])),0)\n",
        "    test_input_first_approach[i] = torch.cat((torch.flatten(test_input[i,0]),torch.flatten(test_input[i,1])),0)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DU6qDtOJT0OQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def k_fold(data, ind, k):\n",
        "    n = len(data)\n",
        "    return data[n * (ind-1)//k:n * ind//k], data[0:n * (ind-1)//k], data[n * ind//k:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPnkqEbwT2F5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "##############################First Model#########################################\n",
        "#Test error rate 19%\n",
        "#Convergence 20 epochs\n",
        "\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(2, 32, kernel_size = 3)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size = 3)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size = 3)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        \n",
        "        self.fc1 = nn.Linear(128, 100)\n",
        "        self.out = nn.Linear(100, 2)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.bn1(x)\n",
        "        \n",
        "        x = F.relu(F.max_pool2d(self.conv2(x), stride = 2, kernel_size = 2))\n",
        "        x = self.bn2(x)\n",
        "        \n",
        "        x = F.relu(F.max_pool2d(self.conv3(x), stride = 2, kernel_size = 2))\n",
        "        x = self.bn3(x)\n",
        "        \n",
        "        x = F.relu(self.fc1(x.view(-1,128)))\n",
        "        x = self.out(x)\n",
        "        \n",
        "        return x\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwfqG8_1T4EN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "###############################Second Model#####################################\n",
        "# Error rate 13-14%\n",
        "# Convergence fast\n",
        "# Computationally more expensive \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class NetWeightSharing(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NetWeightSharing, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size = 3)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size = 3)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size = 3)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        \n",
        "        self.fc1 = nn.Linear(128, 100)\n",
        "        \n",
        "        self.out = nn.Linear(200, 2)\n",
        "    \n",
        "    def sharing_layers(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.bn1(x)\n",
        "        \n",
        "        x = F.relu(F.max_pool2d(self.conv2(x), stride = 2, kernel_size = 2))\n",
        "        x = self.bn2(x)\n",
        "        \n",
        "        x = F.relu(F.max_pool2d(self.conv3(x), stride = 2, kernel_size = 2))\n",
        "        x = self.bn3(x)\n",
        "        x = F.relu(self.fc1(x.view(-1,128)))\n",
        "        return x\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x1 = self.sharing_layers(x[:,0].unsqueeze(1))\n",
        "        x2 = self.sharing_layers(x[:,1].unsqueeze(1))\n",
        "        \n",
        "        output = torch.cat((x1,x2),1)\n",
        "        output = self.out(output)\n",
        "        \n",
        "        return output\n",
        "        \n",
        "        \n",
        "        \n",
        "model = NetWeightSharing()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LMYbHqET5sd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "#####################################Third Model###########################################\n",
        "#Error rate 10.9%\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class NetAux_Share(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NetAux_Share, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size = 3)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size = 3)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size = 3)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        \n",
        "        self.fc1 = nn.Linear(128, 100)\n",
        "        \n",
        "        self.out1 = nn.Linear(100, 10)\n",
        "        self.out2 = nn.Linear(100, 10)\n",
        "        \n",
        "        self.out = nn.Linear(20, 2)\n",
        "    \n",
        "    def sharing_layers(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.bn1(x)\n",
        "        \n",
        "        x = F.relu(F.max_pool2d(self.conv2(x), stride = 2, kernel_size = 2))\n",
        "        x = self.bn2(x)\n",
        "        \n",
        "        x = F.relu(F.max_pool2d(self.conv3(x), stride = 2, kernel_size = 2))\n",
        "        x = self.bn3(x)\n",
        "        x = F.relu(self.fc1(x.view(-1,128)))\n",
        "        return x\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x1 = self.sharing_layers(x[:,0].unsqueeze(1))\n",
        "        x2 = self.sharing_layers(x[:,1].unsqueeze(1))\n",
        "        \n",
        "        x1 = self.out1(x1)\n",
        "        x2 = self.out2(x2)\n",
        "        \n",
        "        output = torch.cat((x1,x2),1)\n",
        "        \n",
        "        output = self.out(output)\n",
        "        \n",
        "        return output, x1, x2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWXq1WuAT7nD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "################################FULLY CONNECTED NETWORK#################################\n",
        "\n",
        "class SimpleFCNetwork(nn.Module):\n",
        "    def __init__(self, h_shapes):\n",
        "       \n",
        "        super().__init__()\n",
        "        self.length = len(h_shapes)\n",
        "        self.hidden_l = nn.ModuleList()\n",
        "        for i in range(len(h_shapes)-1):\n",
        "            self.hidden_l.append(nn.Linear(h_shapes[i], h_shapes[i+1]))\n",
        "        \n",
        "        \n",
        "        self.fc1 = nn.Linear(392, h_shapes[0])\n",
        "        self.fc3 = nn.Linear(h_shapes[self.length-1], 2)\n",
        "       \n",
        "        \n",
        "    def forward(self, x):\n",
        "      \n",
        "  \n",
        "        x = F.relu(self.fc1(x))\n",
        "     \n",
        "        for i in range(self.length-1):\n",
        "          x = F.relu(self.hidden_l[i](x))\n",
        "      \n",
        "        x = F.relu(self.fc3(x))\n",
        "       \n",
        "        return x\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxyyviA7UIJs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################FULLY CONNECTED NETWORK WITH AUX LOSS#################################\n",
        "\n",
        "\n",
        "class FCAux(nn.Module):\n",
        "    def __init__(self, h_shapes):\n",
        "       \n",
        "        super().__init__()\n",
        "        self.length = len(h_shapes)\n",
        "        self.hidden_l = nn.ModuleList()\n",
        "        for i in range(len(h_shapes)-1):\n",
        "            self.hidden_l.append(nn.Linear(h_shapes[i], h_shapes[i+1]))\n",
        "        \n",
        "       \n",
        "        self.fc1 = nn.Linear(392, h_shapes[0])\n",
        "        self.fc3 = nn.Linear(h_shapes[self.length-1], 2)\n",
        "        self.fc4 = nn.Linear(h_shapes[self.length-1], 10)\n",
        "        self.fc5 = nn.Linear(h_shapes[self.length-1], 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "  \n",
        "        \n",
        "        x = F.relu(self.fc1(x))\n",
        "        \n",
        "        for i in range(self.length-1):\n",
        "          x = F.relu(self.hidden_l[i](x))\n",
        "\n",
        "        y = F.relu(self.fc4(x))\n",
        "        z = F.relu(self.fc5(x))\n",
        "        \n",
        "        x = F.relu(self.fc3(x))\n",
        "       \n",
        "        return x, y, z\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJoZHC2vUPbc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "################################PRECISION-RECALL CURVE#################################\n",
        "def precision_recall(target, pred):\n",
        "  \n",
        "  target = [True if x else False for x in target]\n",
        "  sorted_ind = sorted(range(len(list(pred))), key=lambda k: list(pred)[k])\n",
        "  sorted_ind.reverse()\n",
        "\n",
        "  pred = [pred[i] for i in sorted_ind]\n",
        "\n",
        "  target = [target[i] for i in sorted_ind]\n",
        "\n",
        "  uniqs = list(set(list(pred)))\n",
        "  uniqs.sort(reverse=True)\n",
        "  \n",
        "  indexes = [list(pred).index(x) for x in uniqs]\n",
        "\n",
        "  t = [1 if x else 0 for x in target]\n",
        "  tp_accum = list(accumulate(t))\n",
        "  \n",
        "  \n",
        "  tps = [tp_accum[i] for i in indexes]\n",
        "\n",
        "  ones = [1]*(len(target))\n",
        "  fp_accum = list(accumulate([a_i - b_i for a_i, b_i in zip(ones, t)]))\n",
        "  fps = [1+t-tp for t,tp in zip(indexes,tps)]\n",
        "\n",
        "  \n",
        "  precision = [x/(x + y) if x+y else 0 for x,y in zip(tps,fps)]\n",
        "  recall =  [x/tps[-1] if tps[-1] else 0 for x in tps]\n",
        "\n",
        "  thresholds = [pred[i] for i in indexes]\n",
        "  \n",
        "  last_ind = len(tps)-2\n",
        "  sl = slice(last_ind, None, -1)\n",
        "\n",
        "  pre = precision[sl]\n",
        "  pre.append(1.0)\n",
        "  rec = recall[sl]\n",
        "  rec.append(0.0)\n",
        "  return pre, rec, thresholds[sl]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ch4v0KM1URRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################ROC CURVE#################################\n",
        "\n",
        "def roc_true(target, pred):\n",
        "  \n",
        "  target = [True if x else False for x in target]\n",
        "  sorted_ind = sorted(range(len(list(pred))), key=lambda k: list(pred)[k])\n",
        "  sorted_ind.reverse()\n",
        " \n",
        "  pred = [pred[i] for i in sorted_ind]\n",
        "\n",
        "  target = [target[i] for i in sorted_ind]\n",
        "\n",
        "  uniqs = list(set(list(pred)))\n",
        "  uniqs.sort(reverse=True)\n",
        "  \n",
        "  indexes = [list(pred).index(x) for x in uniqs]\n",
        "  \n",
        "\n",
        "  t = [1 if x else 0 for x in target]\n",
        "  tp_accum = list(accumulate(t))\n",
        "  \n",
        "  \n",
        "  tps = [tp_accum[i] for i in indexes]\n",
        "\n",
        "  ones = [1]*(len(target))\n",
        "  fp_accum = list(accumulate([a_i - b_i for a_i, b_i in zip(ones, t)]))\n",
        "  fps = [1+t-tp for t,tp in zip(indexes,tps)]\n",
        "\n",
        "  thresholds = [pred[i] for i in indexes]\n",
        "\n",
        "  thresholds.insert(0, thresholds[0] + 1)\n",
        "  tps.insert(0, 0)\n",
        "  fps.insert(0, 0)\n",
        "  fpr = [i/fps[-1] for i in fps]\n",
        "  tpr = [i/tps[-1] for i in tps]\n",
        "\n",
        "  return fpr, tpr, thresholds\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VE1LmTKWUWIf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b9388ca2-ba34-41a3-9163-efc1ea991eb4"
      },
      "source": [
        "\n",
        "\n",
        "################################Training Function#################################\n",
        "def training_model(train_input, train_target, model, batch, lr):\n",
        "    model.to(device)\n",
        "    train_input.to(device)\n",
        "    train_target.to(device)\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr = lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    total_loss = 0\n",
        "    for b in range(0, train_input.size(0), batch):\n",
        "        output = model(train_input.narrow(0, b, batch).to(device))            \n",
        "        loss = criterion(output, train_target.narrow(0, b, batch).to(device))\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss \n",
        "\n",
        "\n",
        "def compute_nb_errors(model, data_input, data_target, batch):\n",
        "    model.to(device)\n",
        "    data_input.to(device)\n",
        "    data_target.to(device)\n",
        "    nb_data_errors = 0\n",
        "\n",
        "    for b in range(0, data_input.size(0), batch):\n",
        "        output = model(data_input.narrow(0, b, batch).to(device))\n",
        "        _, predicted_classes = torch.max(output, 1)\n",
        "        for k in range(batch):\n",
        "            if data_target[b + k] != predicted_classes[k]:\n",
        "                nb_data_errors = nb_data_errors + 1\n",
        "    return nb_data_errors\n",
        "\n",
        "##########################Train Aux Function########################################\n",
        "    \n",
        "def training_aux(CNNFlag, train_input, train_target, train_classes, model, batch, lr):\n",
        "    model.to(device)\n",
        "    train_input.to(device)\n",
        "    train_target.to(device)\n",
        "    train_classes.to(device)\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr = lr)\n",
        "    Binary_Criterion = nn.CrossEntropyLoss()\n",
        "    Aux_Criterion = nn.CrossEntropyLoss()\n",
        "    total_loss_aux = 0\n",
        "    total_loss_bin = 0\n",
        "    final_total_loss = 0\n",
        "    for b in range(0, train_input.size(0), batch):\n",
        "     \n",
        "      output, aux1, aux2 = model(train_input.narrow(0, b, batch).to(device))\n",
        "      \n",
        "      target_classes = train_classes.narrow(0, b, batch).to(device)\n",
        "      target_comparison = train_target.narrow(0, b, batch).to(device)\n",
        "    \n",
        "      aux_loss = Aux_Criterion(aux1, target_classes[:,0].to(device)) + Aux_Criterion(aux2, target_classes[:,1].to(device))\n",
        "     \n",
        "      binary_loss = Binary_Criterion(output, target_comparison)\n",
        "      final_loss = 0.7*binary_loss + 0.3*aux_loss\n",
        "      model.zero_grad()\n",
        "      final_loss.backward()\n",
        "      optimizer.step()\n",
        "      total_loss_aux += aux_loss\n",
        "      total_loss_bin += binary_loss\n",
        "      final_total_loss += final_loss\n",
        "    return final_total_loss, total_loss_aux, total_loss_bin\n",
        "\n",
        "def compute_nb_errors_aux(CNNFlag, model, data_input, data_target, batch):\n",
        "    model.to(device)\n",
        "    data_input.to(device)\n",
        "    data_target.to(device)\n",
        "    \n",
        "    nb_data_errors = 0\n",
        "\n",
        "    for b in range(0, data_input.size(0), batch):\n",
        "      \n",
        "      output,_,_ = model(data_input.narrow(0, b, batch).to(device))\n",
        "      \n",
        "      _, predicted_classes = torch.max(output, 1)\n",
        "      for k in range(batch):\n",
        "          if data_target[b + k] != predicted_classes[k]:\n",
        "              nb_data_errors = nb_data_errors + 1\n",
        "    return nb_data_errors\n",
        "\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xfpn1wcZ-BB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_until_convergence(CNNFlag, AuxFlag, model, training_data, training_target, training_classes, batch, l):\n",
        "  prev_loss = 999999\n",
        "  #TRAIN UNTIL CINVERGENCE\n",
        "  epochs = 0\n",
        "  while(True):\n",
        "    epochs += 1\n",
        "    if not AuxFlag:\n",
        "      cur_loss = training_model(training_data, training_target, model, batch, l)\n",
        "    else:\n",
        "      cur_loss, _, _ = training_aux(CNNFlag, training_data, training_target, training_classes, model, batch, l)\n",
        "    \n",
        "    \n",
        "    if(abs(prev_loss - cur_loss) <= 0.001):\n",
        "      break\n",
        "    prev_loss = cur_loss\n",
        "  return epochs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAJrmSViaQuK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def report_error(CNNFlag, AuxFlag, model, test_data, test_target, batch):\n",
        "  error = 0\n",
        "  if not AuxFlag: \n",
        "    error = compute_nb_errors(model, test_data,test_target, batch)\n",
        "  else:\n",
        "    error = compute_nb_errors_aux(CNNFlag, model, test_data,test_target, batch)\n",
        "  return error\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGliPciAUXws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################HYPERPARAMETER TUNING WITH CROSSVALIDATION#################################\n",
        "def cross_validation_tuning(CNNFlag, AuxFlag,WeightshareFlag,train_data, train_target, training_classes, k, lr, batches, neurons = None):\n",
        "  err_min = 999999\n",
        "  \n",
        "\n",
        "  #TUNING NUMBER OF BATCHES\n",
        "  for batch in batches:\n",
        "    #TUNING LEARNING RATE\n",
        "    for l in lr:\n",
        "      #CHECKING IF TUNING IS FIR A CNN NETWORK\n",
        "      if(not CNNFlag):\n",
        "        #TUNING FOR NUMBER OF HIDDEN LAYERS FOR FC NETWORK\n",
        "        for neuron_count in neurons:\n",
        "          error = 0\n",
        "          #CROSS VALIDATION\n",
        "          for i in range(1, k + 1): \n",
        "            if not AuxFlag:\n",
        "              model = SimpleFCNetwork(neuron_count)\n",
        "            else:\n",
        "              model = FCAux(neuron_count)\n",
        "            #FOLDING THE DATA\n",
        "            test_data, train_1_data, train_2_data = k_fold(train_data, i, k)\n",
        "            test_target, train_1_target, train_2_target = k_fold(train_target, i, k)\n",
        "            training_data = torch.cat((train_1_data,train_2_data),0)\n",
        "            training_target = torch.cat((train_1_target,train_2_target),0)\n",
        "            prev_loss = 999999\n",
        "            #TRAIN UNTIL CINVERGENCE\n",
        "            train_until_convergence(CNNFlag, AuxFlag, model, training_data, training_target, train_classes, batch, l)\n",
        "\n",
        "            error += report_error(CNNFlag, AuxFlag, model, test_data, test_target, batch)\n",
        "          error /= k\n",
        "          \n",
        "          if error < err_min:\n",
        "            err_min = error\n",
        "            l_min = l\n",
        "            batch_min = batch\n",
        "            neruron_min =  neuron_count if neurons else None\n",
        "      #NUMBER OF HIDDEN LAYERS IS NOT TUNED FOR CNN\n",
        "      else:\n",
        "       \n",
        "        error = 0\n",
        "        #CROSS VALIDATION\n",
        "        for i in range(1, k + 1): \n",
        "          #FOLDING THE DATA\n",
        "          test_data, train_1_data, train_2_data = k_fold(train_data, i, k)\n",
        "          test_target, train_1_target, train_2_target = k_fold(train_target, i, k)\n",
        "          training_data = torch.cat((train_1_data,train_2_data),0)\n",
        "          training_target = torch.cat((train_1_target,train_2_target),0)\n",
        "          if not AuxFlag:\n",
        "            if not WeightshareFlag:\n",
        "              model = SimpleNet()\n",
        "            else:\n",
        "              model = NetWeightSharing()\n",
        "          else:\n",
        "            model = NetAux_Share()\n",
        "          prev_loss = 999999\n",
        "          #TRAIN UNTIL CONVERGENCE\n",
        "          train_until_convergence(CNNFlag, AuxFlag, model, training_data, training_target, train_classes, batch, l)\n",
        " \n",
        "\n",
        "          error += report_error(CNNFlag, AuxFlag, model, test_data, test_target, batch)\n",
        "        error /= k\n",
        "\n",
        "       \n",
        "        #TAKE THE HYPERPARAMETERS WITH MINIMAL ERROR\n",
        "        if error < err_min:\n",
        "          err_min = error\n",
        "          l_min = l\n",
        "          batch_min = batch\n",
        "          neruron_min =  neuron_count if neurons else None\n",
        "  return err_min, l_min, batch_min, neruron_min\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF3_7518gfs9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_predictions(CNNFlag, AuxFlag, model, test_input):\n",
        "  if not AuxFlag:\n",
        "    output = model(test_input.to(device))\n",
        "  else:\n",
        "    output, _, _ = model(test_input.to(device))\n",
        " \n",
        "\n",
        "  m = nn.Softmax()\n",
        "  probs = m(output)\n",
        "  return probs[:, 1]\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZZZBoNqePIU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_roc_curve(test_target, predictions, titles):\n",
        "  for i in range(len(titles)):\n",
        "    fpr, tpr, _  = (roc_true(test_target, predictions[i]))\n",
        "    plt.plot(fpr, tpr, marker=',', label=titles[i])\n",
        "  \n",
        " \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iS_bscfWfqpq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def  plot_precision_recall_curve(test_target, predictions, titles):\n",
        "  for i in range(len(titles)):\n",
        "    lr_recall, lr_precision, _  = (precision_recall(test_target, predictions[i]))\n",
        "    plt.plot(lr_recall, lr_precision, marker=',', label=titles[i])\n",
        "  \n",
        " \n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcubmjdZi9f0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################# TUNING OUR MODELS ###########\n",
        "optimal_parameters = []\n",
        "#Tuning basic CNN\n",
        "optimal_parameters.append( cross_validation_tuning(True, False,False, train_input, train_target, train_classes,10,[0.1,0.05,0.01,0.005],[100, 50, 20]))\n",
        "#Tuning for weight shared CNN with no Aux loss\n",
        "optimal_parameters.append( cross_validation_tuning(True, False,True, train_input, train_target, train_classes,10,[0.1,0.05,0.01,0.005],[100, 50, 20]))\n",
        "#Tuning for weight shared CNN with Aux loss\n",
        "optimal_parameters.append( cross_validation_tuning(True, True,True, train_input, train_target, train_classes,10,[0.1,0.05,0.01,0.005],[100, 50, 20]))\n",
        "#Tuning for FC network with no Aux loss\n",
        "optimal_parameters.append( cross_validation_tuning(False, False,False, train_input_first_approach, train_target, train_classes,10,[0.1,0.005,0.01,0.05,0.001],[100, 50, 20],[[200, 50, 10],[150, 100],[2000,100],[150, 50,20, 10],[5000]]))\n",
        "#Tuning for FC network with Aux loss\n",
        "optimal_parameters.append( cross_validation_tuning(False, True,False, train_input_first_approach, train_target, train_classes,10,[0.1,0.005,0.01,0.05,0.001],[100, 50, 20],[[200, 50, 10],[150, 100],[2000,100],[150, 50,20, 10],[5000]]))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIZF3GSy-IVU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#OUTPITTING OPTIMAL PARAMETERS FOR EACH MODEL\n",
        "print(optimal_parameters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4SxV-6mvH_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#############################Training Part###############################\n",
        "RandomSeeds = list(range(1,11))\n",
        "predictions_of_models = []\n",
        "titles = [\"Basic CNN\",\"CNN weight sharing\",\"CNN weight sharing & Aux loss\", \"FC network\",\"FC Network with Aux loss\"]\n",
        "mean_predictions = 0\n",
        "mean_epochs = 0\n",
        "errors = []\n",
        "for seed in RandomSeeds:\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  model = SimpleNet()\n",
        "  number_of_epochs = train_until_convergence(True, False, model, train_input, train_target, train_classes, optimal_parameters[0][2], optimal_parameters[0][1])\n",
        "  mean_epochs += number_of_epochs\n",
        "  error = report_error(True, False, model, test_input, test_target, optimal_parameters[0][2])/len(test_target)\n",
        "  \n",
        "  errors.append(error)\n",
        "  mean_predictions += get_predictions(True, False,model, test_input)\n",
        "  \n",
        "\n",
        "\n",
        "mean_predictions /= len(RandomSeeds)\n",
        "mean_epochs /= len(RandomSeeds)\n",
        "print(\"Average number of epochs until convergence:\", mean_epochs)\n",
        "mean_error = statistics.mean(errors)\n",
        "print(\"Mean of errors:\", mean_error)\n",
        "std_error = statistics.stdev(errors)\n",
        "print(\"Standard deviation of errors:\", std_error)\n",
        "predictions_of_models.append(torch.flatten(mean_predictions).tolist())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDOjIp_-dtrB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "mean_predictions = 0\n",
        "mean_epochs = 0\n",
        "errors = []\n",
        "for seed in RandomSeeds:\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  model = NetWeightSharing()\n",
        "  number_of_epochs = train_until_convergence(True, False, model, train_input, train_target, train_classes, optimal_parameters[1][2], optimal_parameters[1][1])\n",
        "  mean_epochs += number_of_epochs\n",
        "  error = report_error(True, False, model, test_input, test_target, optimal_parameters[1][2])/len(test_target)\n",
        "  \n",
        "  errors.append(error)\n",
        "  mean_predictions += get_predictions(True, False,model, test_input)\n",
        "  \n",
        "\n",
        "\n",
        "mean_predictions /= len(RandomSeeds)\n",
        "mean_epochs /= len(RandomSeeds)\n",
        "print(\"Average number of epochs until convergence:\", mean_epochs)\n",
        "mean_error = statistics.mean(errors)\n",
        "print(\"Mean of errors:\", mean_error)\n",
        "std_error = statistics.stdev(errors)\n",
        "print(\"Standard deviation of errors:\", std_error)\n",
        "predictions_of_models.append(torch.flatten(mean_predictions).tolist())\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKerpnEwidnv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "mean_predictions = 0\n",
        "mean_epochs = 0\n",
        "errors = []\n",
        "for seed in RandomSeeds:\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  model = NetAux_Share()\n",
        "  number_of_epochs = train_until_convergence(True, True, model, train_input, train_target, train_classes, optimal_parameters[2][2], optimal_parameters[2][1])\n",
        "  mean_epochs += number_of_epochs\n",
        "  error = report_error(True, True, model, test_input, test_target, optimal_parameters[2][2])/len(test_target)\n",
        "  errors.append(error)\n",
        " \n",
        "  mean_predictions += get_predictions(True, True, model, test_input)\n",
        "  \n",
        "\n",
        "mean_predictions /= len(RandomSeeds)\n",
        "mean_epochs /= len(RandomSeeds)\n",
        "print(\"Average number of epochs until convergence:\", mean_epochs)\n",
        "mean_error = statistics.mean(errors)\n",
        "print(\"Mean of errors:\", mean_error)\n",
        "std_error = statistics.stdev(errors)\n",
        "print(\"Standard deviation of errors:\", std_error)\n",
        "predictions_of_models.append(mean_predictions)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f26nAEn-jSVC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "mean_predictions = 0\n",
        "mean_epochs = 0\n",
        "errors = []\n",
        "for seed in RandomSeeds:\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  model = SimpleFCNetwork(optimal_parameters[3][3])\n",
        "  \n",
        "  number_of_epochs = train_until_convergence(False, False, model, train_input_first_approach, train_target, train_classes, optimal_parameters[3][2], optimal_parameters[3][1])\n",
        "  mean_epochs += number_of_epochs\n",
        "  error = report_error(False, False, model, test_input_first_approach, test_target, optimal_parameters[3][2])/len(test_target)\n",
        "  errors.append(error)\n",
        "  \n",
        " \n",
        "  mean_predictions += get_predictions(False, False, model, test_input_first_approach)\n",
        "  \n",
        "\n",
        "mean_predictions /= len(RandomSeeds)\n",
        "mean_epochs /= len(RandomSeeds)\n",
        "print(\"Average number of epochs until convergence:\", mean_epochs)\n",
        "mean_error = statistics.mean(errors)\n",
        "print(\"Mean of errors:\", mean_error)\n",
        "std_error = statistics.stdev(errors)\n",
        "print(\"Standard deviation of errors:\", std_error)\n",
        "predictions_of_models.append(torch.flatten(mean_predictions).tolist())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgP-DddKcLDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "mean_predictions = 0\n",
        "mean_epochs = 0\n",
        "errors = []\n",
        "for seed in RandomSeeds:\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  model = FCAux(optimal_parameters[4][3])\n",
        "  \n",
        "  number_of_epochs = train_until_convergence(False, True, model, train_input_first_approach, train_target, train_classes, optimal_parameters[4][2], optimal_parameters[4][1])\n",
        "  mean_epochs += number_of_epochs\n",
        "  error = report_error(False, True, model, test_input_first_approach, test_target, optimal_parameters[4][2])/len(test_target)\n",
        "  errors.append(error)\n",
        "  \n",
        " \n",
        "  mean_predictions += get_predictions(False, True, model, test_input_first_approach)\n",
        "  \n",
        "\n",
        "mean_predictions /= len(RandomSeeds)\n",
        "mean_epochs /= len(RandomSeeds)\n",
        "print(\"Average number of epochs until convergence:\", mean_epochs)\n",
        "mean_error = statistics.mean(errors)\n",
        "print(\"Mean of errors:\", mean_error)\n",
        "std_error = statistics.stdev(errors)\n",
        "print(\"Standard deviation of errors:\", std_error)\n",
        "predictions_of_models.append(torch.flatten(mean_predictions).tolist())\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSo3KHOvpKpg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "plot_precision_recall_curve(test_target.tolist(), predictions_of_models, titles)\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision - Recall Curves ')\n",
        "\n",
        "plt.legend()\n",
        "# Display a figure.\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K92k0NB4og8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_roc_curve(test_target.tolist(), predictions_of_models, titles)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves ')\n",
        "plt.legend()\n",
        "# Display a figure.\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}